{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7385125,"sourceType":"datasetVersion","datasetId":4292462}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:12:49.858733Z","iopub.execute_input":"2024-01-15T17:12:49.859554Z","iopub.status.idle":"2024-01-15T17:13:01.217334Z","shell.execute_reply.started":"2024-01-15T17:12:49.859511Z","shell.execute_reply":"2024-01-15T17:13:01.216377Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set your data directory\ndata_dir = '/kaggle/input/brahmi-dataset/data/'\nbatch_size = 32\nimage_size = (128, 128)\nnum_classes = 344  # Update with the actual number of classes\n\n# Enhanced data augmentation for training\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=10,  # Increased rotation range\n    width_shift_range=0.1,  # Increased width shift range\n    height_shift_range=0.1,  # Increased height shift range\n    brightness_range=[0.9, 1.1],  # Expanded brightness range\n    zoom_range=0.1,  # Increased zoom range\n    horizontal_flip=False,  # Allowing horizontal flipping\n    vertical_flip=False,  # Allowing vertical flipping\n    shear_range=0.1,  # Increased shear range\n    fill_mode='nearest',\n    validation_split=0.15\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:13:01.219087Z","iopub.execute_input":"2024-01-15T17:13:01.219754Z","iopub.status.idle":"2024-01-15T17:13:01.226849Z","shell.execute_reply.started":"2024-01-15T17:13:01.219715Z","shell.execute_reply":"2024-01-15T17:13:01.225845Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Create generators for training and validation\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True,\n    subset='training'  # Specify subset as 'training' for the training generator\n)\n\nval_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False,\n    subset='validation'  # Specify subset as 'validation' for the validation generator\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:13:01.228090Z","iopub.execute_input":"2024-01-15T17:13:01.228361Z","iopub.status.idle":"2024-01-15T17:13:02.306641Z","shell.execute_reply.started":"2024-01-15T17:13:01.228337Z","shell.execute_reply":"2024-01-15T17:13:02.305827Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 6698 images belonging to 344 classes.\nFound 1182 images belonging to 344 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Deeper model architecture with pooling and regularization\nmodel = tf.keras.Sequential([\n    Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.3),\n\n    Conv2D(128, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.3),\n\n    Conv2D(256, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.5),\n\n    Flatten(),\n\n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n\n    Dense(num_classes, activation='softmax')\n])\n\n# Compile the model using Adam optimizer with momentum\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:13:02.308620Z","iopub.execute_input":"2024-01-15T17:13:02.308920Z","iopub.status.idle":"2024-01-15T17:13:03.496127Z","shell.execute_reply.started":"2024-01-15T17:13:02.308895Z","shell.execute_reply":"2024-01-15T17:13:03.495150Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-01-15T17:13:03.497354Z","iopub.execute_input":"2024-01-15T17:13:03.497658Z","iopub.status.idle":"2024-01-15T17:13:03.544039Z","shell.execute_reply.started":"2024-01-15T17:13:03.497632Z","shell.execute_reply":"2024-01-15T17:13:03.543239Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 126, 126, 64)      1792      \n                                                                 \n batch_normalization (Batch  (None, 126, 126, 64)      256       \n Normalization)                                                  \n                                                                 \n max_pooling2d (MaxPooling2  (None, 63, 63, 64)        0         \n D)                                                              \n                                                                 \n dropout (Dropout)           (None, 63, 63, 64)        0         \n                                                                 \n conv2d_1 (Conv2D)           (None, 61, 61, 64)        36928     \n                                                                 \n batch_normalization_1 (Bat  (None, 61, 61, 64)        256       \n chNormalization)                                                \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n g2D)                                                            \n                                                                 \n dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n                                                                 \n batch_normalization_2 (Bat  (None, 28, 28, 128)       512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n g2D)                                                            \n                                                                 \n dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 256)               6422784   \n                                                                 \n batch_normalization_3 (Bat  (None, 256)               1024      \n chNormalization)                                                \n                                                                 \n dropout_3 (Dropout)         (None, 256)               0         \n                                                                 \n dense_1 (Dense)             (None, 344)               88408     \n                                                                 \n=================================================================\nTotal params: 6625816 (25.28 MB)\nTrainable params: 6624792 (25.27 MB)\nNon-trainable params: 1024 (4.00 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to adjust learning rate during training\ndef lr_scheduler(epoch, lr):\n    if epoch % 5 == 0 and epoch > 0:\n        lr = lr * 0.75  # Reduce learning rate by 30% every 5 epochs\n    return lr\n\n# Set up the step decay learning rate scheduler callback\nlr_schedule = LearningRateScheduler(lr_scheduler)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # Adjust patience","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:13:03.545052Z","iopub.execute_input":"2024-01-15T17:13:03.545309Z","iopub.status.idle":"2024-01-15T17:13:03.550518Z","shell.execute_reply.started":"2024-01-15T17:13:03.545285Z","shell.execute_reply":"2024-01-15T17:13:03.549630Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Using ImageDataGenerator's flow method during training and validation\nmodel.fit(\n    train_generator,\n    epochs=100,\n    validation_data=val_generator,\n    callbacks=[lr_schedule, early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:13:03.551737Z","iopub.execute_input":"2024-01-15T17:13:03.552357Z","iopub.status.idle":"2024-01-15T18:03:59.537991Z","shell.execute_reply.started":"2024-01-15T17:13:03.552322Z","shell.execute_reply":"2024-01-15T18:03:59.537074Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-01-15 17:13:05.549677: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"210/210 [==============================] - 84s 370ms/step - loss: 5.9549 - accuracy: 0.0245 - val_loss: 9.1788 - val_accuracy: 0.0127 - lr: 0.0010\nEpoch 2/100\n210/210 [==============================] - 46s 221ms/step - loss: 5.1684 - accuracy: 0.0578 - val_loss: 13.3567 - val_accuracy: 0.0085 - lr: 0.0010\nEpoch 3/100\n210/210 [==============================] - 47s 222ms/step - loss: 4.6983 - accuracy: 0.0944 - val_loss: 5.0251 - val_accuracy: 0.0584 - lr: 0.0010\nEpoch 4/100\n210/210 [==============================] - 47s 223ms/step - loss: 4.1221 - accuracy: 0.1500 - val_loss: 6.9993 - val_accuracy: 0.0228 - lr: 0.0010\nEpoch 5/100\n210/210 [==============================] - 47s 222ms/step - loss: 3.5958 - accuracy: 0.2154 - val_loss: 3.9635 - val_accuracy: 0.1531 - lr: 0.0010\nEpoch 6/100\n210/210 [==============================] - 48s 227ms/step - loss: 3.0922 - accuracy: 0.2916 - val_loss: 4.2578 - val_accuracy: 0.1277 - lr: 7.5000e-04\nEpoch 7/100\n210/210 [==============================] - 48s 227ms/step - loss: 2.7738 - accuracy: 0.3519 - val_loss: 3.3142 - val_accuracy: 0.2555 - lr: 7.5000e-04\nEpoch 8/100\n210/210 [==============================] - 47s 226ms/step - loss: 2.4435 - accuracy: 0.4152 - val_loss: 2.8627 - val_accuracy: 0.3173 - lr: 7.5000e-04\nEpoch 9/100\n210/210 [==============================] - 47s 224ms/step - loss: 2.2148 - accuracy: 0.4498 - val_loss: 2.1413 - val_accuracy: 0.4848 - lr: 7.5000e-04\nEpoch 10/100\n210/210 [==============================] - 48s 227ms/step - loss: 1.9980 - accuracy: 0.4912 - val_loss: 2.3201 - val_accuracy: 0.4281 - lr: 7.5000e-04\nEpoch 11/100\n210/210 [==============================] - 48s 227ms/step - loss: 1.7765 - accuracy: 0.5436 - val_loss: 1.9743 - val_accuracy: 0.5431 - lr: 5.6250e-04\nEpoch 12/100\n210/210 [==============================] - 47s 224ms/step - loss: 1.6358 - accuracy: 0.5633 - val_loss: 5.4441 - val_accuracy: 0.2098 - lr: 5.6250e-04\nEpoch 13/100\n210/210 [==============================] - 47s 225ms/step - loss: 1.4974 - accuracy: 0.6082 - val_loss: 2.0516 - val_accuracy: 0.5457 - lr: 5.6250e-04\nEpoch 14/100\n210/210 [==============================] - 47s 224ms/step - loss: 1.3665 - accuracy: 0.6348 - val_loss: 1.6834 - val_accuracy: 0.5922 - lr: 5.6250e-04\nEpoch 15/100\n210/210 [==============================] - 48s 226ms/step - loss: 1.2736 - accuracy: 0.6533 - val_loss: 1.3088 - val_accuracy: 0.6531 - lr: 5.6250e-04\nEpoch 16/100\n210/210 [==============================] - 47s 223ms/step - loss: 1.1989 - accuracy: 0.6687 - val_loss: 3.5530 - val_accuracy: 0.1785 - lr: 4.2187e-04\nEpoch 17/100\n210/210 [==============================] - 48s 227ms/step - loss: 1.0880 - accuracy: 0.6996 - val_loss: 1.1072 - val_accuracy: 0.7360 - lr: 4.2187e-04\nEpoch 18/100\n210/210 [==============================] - 47s 223ms/step - loss: 1.0123 - accuracy: 0.7250 - val_loss: 1.2968 - val_accuracy: 0.6954 - lr: 4.2187e-04\nEpoch 19/100\n210/210 [==============================] - 47s 223ms/step - loss: 0.9767 - accuracy: 0.7342 - val_loss: 2.5848 - val_accuracy: 0.5795 - lr: 4.2187e-04\nEpoch 20/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.9495 - accuracy: 0.7354 - val_loss: 2.0718 - val_accuracy: 0.5931 - lr: 4.2187e-04\nEpoch 21/100\n210/210 [==============================] - 47s 221ms/step - loss: 0.8855 - accuracy: 0.7543 - val_loss: 1.1100 - val_accuracy: 0.6887 - lr: 3.1641e-04\nEpoch 22/100\n210/210 [==============================] - 46s 221ms/step - loss: 0.8260 - accuracy: 0.7717 - val_loss: 0.8419 - val_accuracy: 0.7716 - lr: 3.1641e-04\nEpoch 23/100\n210/210 [==============================] - 48s 227ms/step - loss: 0.7902 - accuracy: 0.7814 - val_loss: 0.9899 - val_accuracy: 0.7377 - lr: 3.1641e-04\nEpoch 24/100\n210/210 [==============================] - 48s 229ms/step - loss: 0.7299 - accuracy: 0.7926 - val_loss: 0.6253 - val_accuracy: 0.8519 - lr: 3.1641e-04\nEpoch 25/100\n210/210 [==============================] - 48s 227ms/step - loss: 0.7148 - accuracy: 0.7959 - val_loss: 1.1166 - val_accuracy: 0.7005 - lr: 3.1641e-04\nEpoch 26/100\n210/210 [==============================] - 48s 230ms/step - loss: 0.6845 - accuracy: 0.8082 - val_loss: 0.7332 - val_accuracy: 0.8105 - lr: 2.3730e-04\nEpoch 27/100\n210/210 [==============================] - 48s 227ms/step - loss: 0.6605 - accuracy: 0.8146 - val_loss: 1.2447 - val_accuracy: 0.6684 - lr: 2.3730e-04\nEpoch 28/100\n210/210 [==============================] - 48s 228ms/step - loss: 0.6327 - accuracy: 0.8258 - val_loss: 0.6861 - val_accuracy: 0.8198 - lr: 2.3730e-04\nEpoch 29/100\n210/210 [==============================] - 47s 226ms/step - loss: 0.6113 - accuracy: 0.8255 - val_loss: 1.2168 - val_accuracy: 0.7648 - lr: 2.3730e-04\nEpoch 30/100\n210/210 [==============================] - 47s 223ms/step - loss: 0.5929 - accuracy: 0.8358 - val_loss: 1.2422 - val_accuracy: 0.6574 - lr: 2.3730e-04\nEpoch 31/100\n210/210 [==============================] - 48s 226ms/step - loss: 0.5715 - accuracy: 0.8367 - val_loss: 0.7462 - val_accuracy: 0.7961 - lr: 1.7798e-04\nEpoch 32/100\n210/210 [==============================] - 48s 228ms/step - loss: 0.5660 - accuracy: 0.8389 - val_loss: 0.6987 - val_accuracy: 0.8054 - lr: 1.7798e-04\nEpoch 33/100\n210/210 [==============================] - 48s 227ms/step - loss: 0.5432 - accuracy: 0.8504 - val_loss: 0.5874 - val_accuracy: 0.8418 - lr: 1.7798e-04\nEpoch 34/100\n210/210 [==============================] - 47s 225ms/step - loss: 0.5435 - accuracy: 0.8459 - val_loss: 0.9039 - val_accuracy: 0.7293 - lr: 1.7798e-04\nEpoch 35/100\n210/210 [==============================] - 47s 225ms/step - loss: 0.5337 - accuracy: 0.8485 - val_loss: 1.8950 - val_accuracy: 0.6565 - lr: 1.7798e-04\nEpoch 36/100\n210/210 [==============================] - 48s 227ms/step - loss: 0.5019 - accuracy: 0.8592 - val_loss: 0.7776 - val_accuracy: 0.7724 - lr: 1.3348e-04\nEpoch 37/100\n210/210 [==============================] - 47s 225ms/step - loss: 0.5015 - accuracy: 0.8626 - val_loss: 0.5689 - val_accuracy: 0.8469 - lr: 1.3348e-04\nEpoch 38/100\n210/210 [==============================] - 47s 223ms/step - loss: 0.4804 - accuracy: 0.8655 - val_loss: 0.9840 - val_accuracy: 0.7039 - lr: 1.3348e-04\nEpoch 39/100\n210/210 [==============================] - 47s 225ms/step - loss: 0.4814 - accuracy: 0.8673 - val_loss: 0.4934 - val_accuracy: 0.8697 - lr: 1.3348e-04\nEpoch 40/100\n210/210 [==============================] - 48s 231ms/step - loss: 0.4683 - accuracy: 0.8737 - val_loss: 0.5579 - val_accuracy: 0.8596 - lr: 1.3348e-04\nEpoch 41/100\n210/210 [==============================] - 48s 227ms/step - loss: 0.4569 - accuracy: 0.8735 - val_loss: 0.4890 - val_accuracy: 0.8680 - lr: 1.0011e-04\nEpoch 42/100\n210/210 [==============================] - 48s 226ms/step - loss: 0.4547 - accuracy: 0.8728 - val_loss: 0.7213 - val_accuracy: 0.7902 - lr: 1.0011e-04\nEpoch 43/100\n210/210 [==============================] - 47s 226ms/step - loss: 0.4467 - accuracy: 0.8758 - val_loss: 0.8340 - val_accuracy: 0.7513 - lr: 1.0011e-04\nEpoch 44/100\n210/210 [==============================] - 48s 227ms/step - loss: 0.4546 - accuracy: 0.8686 - val_loss: 0.5617 - val_accuracy: 0.8384 - lr: 1.0011e-04\nEpoch 45/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.4484 - accuracy: 0.8774 - val_loss: 0.4062 - val_accuracy: 0.8900 - lr: 1.0011e-04\nEpoch 46/100\n210/210 [==============================] - 47s 223ms/step - loss: 0.4220 - accuracy: 0.8818 - val_loss: 0.5021 - val_accuracy: 0.8494 - lr: 7.5085e-05\nEpoch 47/100\n210/210 [==============================] - 48s 228ms/step - loss: 0.4177 - accuracy: 0.8852 - val_loss: 0.5424 - val_accuracy: 0.8477 - lr: 7.5085e-05\nEpoch 48/100\n210/210 [==============================] - 49s 233ms/step - loss: 0.4227 - accuracy: 0.8832 - val_loss: 0.4993 - val_accuracy: 0.8697 - lr: 7.5085e-05\nEpoch 49/100\n210/210 [==============================] - 49s 232ms/step - loss: 0.4245 - accuracy: 0.8821 - val_loss: 0.4225 - val_accuracy: 0.8883 - lr: 7.5085e-05\nEpoch 50/100\n210/210 [==============================] - 48s 229ms/step - loss: 0.4051 - accuracy: 0.8891 - val_loss: 0.5071 - val_accuracy: 0.8469 - lr: 7.5085e-05\nEpoch 51/100\n210/210 [==============================] - 47s 224ms/step - loss: 0.3972 - accuracy: 0.8894 - val_loss: 0.5725 - val_accuracy: 0.8283 - lr: 5.6314e-05\nEpoch 52/100\n210/210 [==============================] - 48s 226ms/step - loss: 0.3974 - accuracy: 0.8877 - val_loss: 0.5337 - val_accuracy: 0.8435 - lr: 5.6314e-05\nEpoch 53/100\n210/210 [==============================] - 47s 224ms/step - loss: 0.3977 - accuracy: 0.8877 - val_loss: 0.3657 - val_accuracy: 0.8959 - lr: 5.6314e-05\nEpoch 54/100\n210/210 [==============================] - 47s 224ms/step - loss: 0.3833 - accuracy: 0.8980 - val_loss: 0.4614 - val_accuracy: 0.8706 - lr: 5.6314e-05\nEpoch 55/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.3800 - accuracy: 0.8952 - val_loss: 0.4573 - val_accuracy: 0.8832 - lr: 5.6314e-05\nEpoch 56/100\n210/210 [==============================] - 48s 226ms/step - loss: 0.3899 - accuracy: 0.8943 - val_loss: 0.3971 - val_accuracy: 0.8959 - lr: 4.2235e-05\nEpoch 57/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.3795 - accuracy: 0.8979 - val_loss: 0.4375 - val_accuracy: 0.8756 - lr: 4.2235e-05\nEpoch 58/100\n210/210 [==============================] - 47s 224ms/step - loss: 0.3741 - accuracy: 0.8988 - val_loss: 0.4865 - val_accuracy: 0.8570 - lr: 4.2235e-05\nEpoch 59/100\n210/210 [==============================] - 47s 226ms/step - loss: 0.3797 - accuracy: 0.8943 - val_loss: 0.4478 - val_accuracy: 0.8824 - lr: 4.2235e-05\nEpoch 60/100\n210/210 [==============================] - 47s 226ms/step - loss: 0.3690 - accuracy: 0.8992 - val_loss: 0.3742 - val_accuracy: 0.9044 - lr: 4.2235e-05\nEpoch 61/100\n210/210 [==============================] - 47s 225ms/step - loss: 0.3624 - accuracy: 0.8989 - val_loss: 0.4715 - val_accuracy: 0.8536 - lr: 3.1676e-05\nEpoch 62/100\n210/210 [==============================] - 47s 225ms/step - loss: 0.3717 - accuracy: 0.8952 - val_loss: 0.4236 - val_accuracy: 0.8900 - lr: 3.1676e-05\nEpoch 63/100\n210/210 [==============================] - 47s 225ms/step - loss: 0.3514 - accuracy: 0.9049 - val_loss: 0.4286 - val_accuracy: 0.8773 - lr: 3.1676e-05\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x79c627913760>"},"metadata":{}}]},{"cell_type":"code","source":"# The evaluation is done on the validation set\ntest_loss, test_acc = model.evaluate(val_generator)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T18:03:59.539124Z","iopub.execute_input":"2024-01-15T18:03:59.539405Z","iopub.status.idle":"2024-01-15T18:04:06.729203Z","shell.execute_reply.started":"2024-01-15T18:03:59.539381Z","shell.execute_reply":"2024-01-15T18:04:06.728308Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"37/37 [==============================] - 7s 187ms/step - loss: 0.3855 - accuracy: 0.9002\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('brahmi_recognition_model 9049%.h5')","metadata":{"execution":{"iopub.status.busy":"2024-01-15T18:07:26.543140Z","iopub.execute_input":"2024-01-15T18:07:26.543788Z","iopub.status.idle":"2024-01-15T18:07:26.723809Z","shell.execute_reply.started":"2024-01-15T18:07:26.543742Z","shell.execute_reply":"2024-01-15T18:07:26.722834Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}