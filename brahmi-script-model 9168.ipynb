{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7385125,"sourceType":"datasetVersion","datasetId":4292462}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:21:12.329746Z","iopub.execute_input":"2024-01-15T17:21:12.330320Z","iopub.status.idle":"2024-01-15T17:21:25.387691Z","shell.execute_reply.started":"2024-01-15T17:21:12.330277Z","shell.execute_reply":"2024-01-15T17:21:25.386845Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set your data directory\ndata_dir = '/kaggle/input/brahmi-dataset/data/'\nbatch_size = 32\nimage_size = (128, 128)\nnum_classes = 344  # Update with the actual number of classes\n\n# Enhanced data augmentation for training\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=10,  # Increased rotation range\n    width_shift_range=0.1,  # Increased width shift range\n    height_shift_range=0.1,  # Increased height shift range\n    brightness_range=[0.9, 1.1],  # Expanded brightness range\n    zoom_range=0.1,  # Increased zoom range\n    horizontal_flip=False,  # Allowing horizontal flipping\n    vertical_flip=False,  # Allowing vertical flipping\n    shear_range=0.1,  # Increased shear range\n    fill_mode='nearest',\n    validation_split=0.15\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:21:25.389119Z","iopub.execute_input":"2024-01-15T17:21:25.389666Z","iopub.status.idle":"2024-01-15T17:21:25.396457Z","shell.execute_reply.started":"2024-01-15T17:21:25.389639Z","shell.execute_reply":"2024-01-15T17:21:25.395388Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Create generators for training and validation\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True,\n    subset='training'  # Specify subset as 'training' for the training generator\n)\n\nval_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False,\n    subset='validation'  # Specify subset as 'validation' for the validation generator\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:21:25.397561Z","iopub.execute_input":"2024-01-15T17:21:25.397996Z","iopub.status.idle":"2024-01-15T17:21:26.114678Z","shell.execute_reply.started":"2024-01-15T17:21:25.397967Z","shell.execute_reply":"2024-01-15T17:21:26.113834Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 6698 images belonging to 344 classes.\nFound 1182 images belonging to 344 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Deeper model architecture with pooling and regularization\nmodel = tf.keras.Sequential([\n    Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.3),\n\n    Conv2D(64, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.3),\n\n    Conv2D(128, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.5),\n\n    Flatten(),\n\n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n\n    Dense(num_classes, activation='softmax')\n])\n\n# Compile the model using Adam optimizer with momentum\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:21:26.116611Z","iopub.execute_input":"2024-01-15T17:21:26.116912Z","iopub.status.idle":"2024-01-15T17:21:27.415659Z","shell.execute_reply.started":"2024-01-15T17:21:26.116887Z","shell.execute_reply":"2024-01-15T17:21:27.414925Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-01-15T17:21:27.416973Z","iopub.execute_input":"2024-01-15T17:21:27.417270Z","iopub.status.idle":"2024-01-15T17:21:27.466391Z","shell.execute_reply.started":"2024-01-15T17:21:27.417244Z","shell.execute_reply":"2024-01-15T17:21:27.465607Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 126, 126, 64)      1792      \n                                                                 \n batch_normalization (Batch  (None, 126, 126, 64)      256       \n Normalization)                                                  \n                                                                 \n max_pooling2d (MaxPooling2  (None, 63, 63, 64)        0         \n D)                                                              \n                                                                 \n dropout (Dropout)           (None, 63, 63, 64)        0         \n                                                                 \n conv2d_1 (Conv2D)           (None, 61, 61, 64)        36928     \n                                                                 \n batch_normalization_1 (Bat  (None, 61, 61, 64)        256       \n chNormalization)                                                \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n g2D)                                                            \n                                                                 \n dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n                                                                 \n batch_normalization_2 (Bat  (None, 28, 28, 128)       512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n g2D)                                                            \n                                                                 \n dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 256)               6422784   \n                                                                 \n batch_normalization_3 (Bat  (None, 256)               1024      \n chNormalization)                                                \n                                                                 \n dropout_3 (Dropout)         (None, 256)               0         \n                                                                 \n dense_1 (Dense)             (None, 344)               88408     \n                                                                 \n=================================================================\nTotal params: 6625816 (25.28 MB)\nTrainable params: 6624792 (25.27 MB)\nNon-trainable params: 1024 (4.00 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to adjust learning rate during training\ndef lr_scheduler(epoch, lr):\n    if epoch % 5 == 0 and epoch > 0:\n        lr = lr * 0.9  # Reduce learning rate by 10% every 5 epochs\n    return lr\n\n# Set up the step decay learning rate scheduler callback\nlr_schedule = LearningRateScheduler(lr_scheduler)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # Adjust patience","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:21:27.467636Z","iopub.execute_input":"2024-01-15T17:21:27.467916Z","iopub.status.idle":"2024-01-15T17:21:27.472997Z","shell.execute_reply.started":"2024-01-15T17:21:27.467892Z","shell.execute_reply":"2024-01-15T17:21:27.472104Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Using ImageDataGenerator's flow method during training and validation\nmodel.fit(\n    train_generator,\n    epochs=100,\n    validation_data=val_generator,\n    callbacks=[lr_schedule, early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:21:27.474090Z","iopub.execute_input":"2024-01-15T17:21:27.474357Z","iopub.status.idle":"2024-01-15T18:03:09.585915Z","shell.execute_reply.started":"2024-01-15T17:21:27.474333Z","shell.execute_reply":"2024-01-15T18:03:09.585047Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-01-15 17:21:29.488842: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"210/210 [==============================] - 82s 359ms/step - loss: 5.9830 - accuracy: 0.0203 - val_loss: 8.1358 - val_accuracy: 0.0102 - lr: 0.0010\nEpoch 2/100\n210/210 [==============================] - 48s 229ms/step - loss: 5.1606 - accuracy: 0.0638 - val_loss: 6.9832 - val_accuracy: 0.0127 - lr: 0.0010\nEpoch 3/100\n210/210 [==============================] - 48s 229ms/step - loss: 4.6299 - accuracy: 0.0997 - val_loss: 5.7720 - val_accuracy: 0.0381 - lr: 0.0010\nEpoch 4/100\n210/210 [==============================] - 47s 226ms/step - loss: 4.0695 - accuracy: 0.1596 - val_loss: 6.7475 - val_accuracy: 0.0152 - lr: 0.0010\nEpoch 5/100\n210/210 [==============================] - 47s 225ms/step - loss: 3.4950 - accuracy: 0.2335 - val_loss: 5.1374 - val_accuracy: 0.0719 - lr: 0.0010\nEpoch 6/100\n210/210 [==============================] - 48s 228ms/step - loss: 3.0106 - accuracy: 0.3119 - val_loss: 3.0428 - val_accuracy: 0.3122 - lr: 9.0000e-04\nEpoch 7/100\n210/210 [==============================] - 48s 229ms/step - loss: 2.6506 - accuracy: 0.3656 - val_loss: 2.7704 - val_accuracy: 0.3799 - lr: 9.0000e-04\nEpoch 8/100\n210/210 [==============================] - 48s 229ms/step - loss: 2.3481 - accuracy: 0.4161 - val_loss: 3.0872 - val_accuracy: 0.2953 - lr: 9.0000e-04\nEpoch 9/100\n210/210 [==============================] - 48s 228ms/step - loss: 2.1276 - accuracy: 0.4616 - val_loss: 3.7498 - val_accuracy: 0.2293 - lr: 9.0000e-04\nEpoch 10/100\n210/210 [==============================] - 48s 229ms/step - loss: 1.9091 - accuracy: 0.4999 - val_loss: 2.1388 - val_accuracy: 0.4535 - lr: 9.0000e-04\nEpoch 11/100\n210/210 [==============================] - 48s 227ms/step - loss: 1.6803 - accuracy: 0.5546 - val_loss: 1.8601 - val_accuracy: 0.5406 - lr: 8.1000e-04\nEpoch 12/100\n210/210 [==============================] - 47s 225ms/step - loss: 1.5210 - accuracy: 0.5903 - val_loss: 1.6672 - val_accuracy: 0.5694 - lr: 8.1000e-04\nEpoch 13/100\n210/210 [==============================] - 48s 227ms/step - loss: 1.3694 - accuracy: 0.6250 - val_loss: 1.3019 - val_accuracy: 0.6743 - lr: 8.1000e-04\nEpoch 14/100\n210/210 [==============================] - 48s 227ms/step - loss: 1.3180 - accuracy: 0.6317 - val_loss: 3.8726 - val_accuracy: 0.1904 - lr: 8.1000e-04\nEpoch 15/100\n210/210 [==============================] - 47s 225ms/step - loss: 1.1770 - accuracy: 0.6681 - val_loss: 1.1222 - val_accuracy: 0.6997 - lr: 8.1000e-04\nEpoch 16/100\n210/210 [==============================] - 47s 222ms/step - loss: 1.0744 - accuracy: 0.6993 - val_loss: 1.5177 - val_accuracy: 0.6032 - lr: 7.2900e-04\nEpoch 17/100\n210/210 [==============================] - 47s 224ms/step - loss: 0.9796 - accuracy: 0.7199 - val_loss: 2.4401 - val_accuracy: 0.3486 - lr: 7.2900e-04\nEpoch 18/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.9562 - accuracy: 0.7248 - val_loss: 0.9012 - val_accuracy: 0.7716 - lr: 7.2900e-04\nEpoch 19/100\n210/210 [==============================] - 47s 223ms/step - loss: 0.8688 - accuracy: 0.7478 - val_loss: 0.8137 - val_accuracy: 0.7817 - lr: 7.2900e-04\nEpoch 20/100\n210/210 [==============================] - 46s 221ms/step - loss: 0.8456 - accuracy: 0.7511 - val_loss: 1.2348 - val_accuracy: 0.6379 - lr: 7.2900e-04\nEpoch 21/100\n210/210 [==============================] - 46s 221ms/step - loss: 0.7615 - accuracy: 0.7847 - val_loss: 0.8257 - val_accuracy: 0.7665 - lr: 6.5610e-04\nEpoch 22/100\n210/210 [==============================] - 47s 221ms/step - loss: 0.6983 - accuracy: 0.7981 - val_loss: 1.4006 - val_accuracy: 0.6083 - lr: 6.5610e-04\nEpoch 23/100\n210/210 [==============================] - 47s 223ms/step - loss: 0.6880 - accuracy: 0.7937 - val_loss: 1.3583 - val_accuracy: 0.6125 - lr: 6.5610e-04\nEpoch 24/100\n210/210 [==============================] - 46s 220ms/step - loss: 0.6447 - accuracy: 0.8107 - val_loss: 0.6770 - val_accuracy: 0.8232 - lr: 6.5610e-04\nEpoch 25/100\n210/210 [==============================] - 47s 221ms/step - loss: 0.6482 - accuracy: 0.8052 - val_loss: 1.1537 - val_accuracy: 0.6413 - lr: 6.5610e-04\nEpoch 26/100\n210/210 [==============================] - 48s 227ms/step - loss: 0.6087 - accuracy: 0.8186 - val_loss: 3.5579 - val_accuracy: 0.2606 - lr: 5.9049e-04\nEpoch 27/100\n210/210 [==============================] - 47s 223ms/step - loss: 0.5827 - accuracy: 0.8280 - val_loss: 0.5120 - val_accuracy: 0.8494 - lr: 5.9049e-04\nEpoch 28/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.5636 - accuracy: 0.8356 - val_loss: 1.4974 - val_accuracy: 0.5499 - lr: 5.9049e-04\nEpoch 29/100\n210/210 [==============================] - 46s 221ms/step - loss: 0.5180 - accuracy: 0.8443 - val_loss: 0.6211 - val_accuracy: 0.8037 - lr: 5.9049e-04\nEpoch 30/100\n210/210 [==============================] - 46s 217ms/step - loss: 0.5363 - accuracy: 0.8376 - val_loss: 0.9746 - val_accuracy: 0.7064 - lr: 5.9049e-04\nEpoch 31/100\n210/210 [==============================] - 46s 220ms/step - loss: 0.5011 - accuracy: 0.8462 - val_loss: 0.6248 - val_accuracy: 0.8198 - lr: 5.3144e-04\nEpoch 32/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.4649 - accuracy: 0.8646 - val_loss: 11.0604 - val_accuracy: 0.1007 - lr: 5.3144e-04\nEpoch 33/100\n210/210 [==============================] - 46s 219ms/step - loss: 0.4707 - accuracy: 0.8607 - val_loss: 0.9022 - val_accuracy: 0.7047 - lr: 5.3144e-04\nEpoch 34/100\n210/210 [==============================] - 46s 217ms/step - loss: 0.4456 - accuracy: 0.8623 - val_loss: 0.5597 - val_accuracy: 0.8519 - lr: 5.3144e-04\nEpoch 35/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.4416 - accuracy: 0.8658 - val_loss: 0.4283 - val_accuracy: 0.8883 - lr: 5.3144e-04\nEpoch 36/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.4106 - accuracy: 0.8788 - val_loss: 0.3598 - val_accuracy: 0.8926 - lr: 4.7830e-04\nEpoch 37/100\n210/210 [==============================] - 46s 221ms/step - loss: 0.4045 - accuracy: 0.8716 - val_loss: 0.6171 - val_accuracy: 0.8054 - lr: 4.7830e-04\nEpoch 38/100\n210/210 [==============================] - 46s 218ms/step - loss: 0.4122 - accuracy: 0.8747 - val_loss: 2.7174 - val_accuracy: 0.3646 - lr: 4.7830e-04\nEpoch 39/100\n210/210 [==============================] - 46s 219ms/step - loss: 0.3863 - accuracy: 0.8831 - val_loss: 0.3156 - val_accuracy: 0.9069 - lr: 4.7830e-04\nEpoch 40/100\n210/210 [==============================] - 46s 219ms/step - loss: 0.3852 - accuracy: 0.8859 - val_loss: 0.9506 - val_accuracy: 0.7140 - lr: 4.7830e-04\nEpoch 41/100\n210/210 [==============================] - 46s 220ms/step - loss: 0.3600 - accuracy: 0.8880 - val_loss: 0.6885 - val_accuracy: 0.7792 - lr: 4.3047e-04\nEpoch 42/100\n210/210 [==============================] - 46s 219ms/step - loss: 0.3442 - accuracy: 0.8910 - val_loss: 0.2943 - val_accuracy: 0.9230 - lr: 4.3047e-04\nEpoch 43/100\n210/210 [==============================] - 46s 218ms/step - loss: 0.3394 - accuracy: 0.8952 - val_loss: 0.6235 - val_accuracy: 0.8215 - lr: 4.3047e-04\nEpoch 44/100\n210/210 [==============================] - 46s 218ms/step - loss: 0.3284 - accuracy: 0.9010 - val_loss: 0.4137 - val_accuracy: 0.8892 - lr: 4.3047e-04\nEpoch 45/100\n210/210 [==============================] - 46s 218ms/step - loss: 0.3300 - accuracy: 0.8968 - val_loss: 0.4190 - val_accuracy: 0.8697 - lr: 4.3047e-04\nEpoch 46/100\n210/210 [==============================] - 45s 216ms/step - loss: 0.3204 - accuracy: 0.9031 - val_loss: 0.3938 - val_accuracy: 0.8866 - lr: 3.8742e-04\nEpoch 47/100\n210/210 [==============================] - 46s 219ms/step - loss: 0.3153 - accuracy: 0.9040 - val_loss: 0.4139 - val_accuracy: 0.8714 - lr: 3.8742e-04\nEpoch 48/100\n210/210 [==============================] - 46s 220ms/step - loss: 0.3243 - accuracy: 0.9021 - val_loss: 0.4021 - val_accuracy: 0.8782 - lr: 3.8742e-04\nEpoch 49/100\n210/210 [==============================] - 46s 220ms/step - loss: 0.3123 - accuracy: 0.9037 - val_loss: 0.4003 - val_accuracy: 0.8832 - lr: 3.8742e-04\nEpoch 50/100\n210/210 [==============================] - 47s 222ms/step - loss: 0.3225 - accuracy: 0.9025 - val_loss: 0.5699 - val_accuracy: 0.8240 - lr: 3.8742e-04\nEpoch 51/100\n210/210 [==============================] - 47s 224ms/step - loss: 0.2848 - accuracy: 0.9116 - val_loss: 1.1184 - val_accuracy: 0.6751 - lr: 3.4868e-04\nEpoch 52/100\n210/210 [==============================] - 47s 223ms/step - loss: 0.2693 - accuracy: 0.9168 - val_loss: 0.3008 - val_accuracy: 0.9112 - lr: 3.4868e-04\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7e1d9e9aa860>"},"metadata":{}}]},{"cell_type":"code","source":"# The evaluation is done on the validation set\ntest_loss, test_acc = model.evaluate(val_generator)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T18:03:09.586941Z","iopub.execute_input":"2024-01-15T18:03:09.587228Z","iopub.status.idle":"2024-01-15T18:03:16.614960Z","shell.execute_reply.started":"2024-01-15T18:03:09.587204Z","shell.execute_reply":"2024-01-15T18:03:16.614197Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"37/37 [==============================] - 7s 183ms/step - loss: 0.3157 - accuracy: 0.9086\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the entire model to a HDF5 file\nmodel.save('brahmi_recognition_model 9168%.h5')","metadata":{"execution":{"iopub.status.busy":"2024-01-15T18:05:17.670083Z","iopub.execute_input":"2024-01-15T18:05:17.670943Z","iopub.status.idle":"2024-01-15T18:05:17.865089Z","shell.execute_reply.started":"2024-01-15T18:05:17.670909Z","shell.execute_reply":"2024-01-15T18:05:17.864229Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}